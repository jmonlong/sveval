## prepare arguments based on the config file
REF = config['ref_fa']
## if file ends with .gz, remove the suffix (which will trigger unzipping the fasta)
if REF.endswith('.gz'):
    REF = REF[:-3]

#### Enumerate all the output TSV files
EVALOUT = ['prcurve', 'persize']
REGS = config['regions'].split()
EVAL = config['eval'].split()
EXPS  = config['exp'].split()
METHODS  = config['methods'].split()
SAMPLES = config['samples'].split()
INV = config['check_inv']
PDF =  config['out_pdf']
MIN_COV=config['min_cov']

## Rules
rule all:
    input:
        expand('tsv/{exp}-{method}-{sample}-{region}-{eval}-{evalout}.tsv', exp=EXPS,
               method=METHODS, sample=SAMPLES, region=REGS, eval=EVAL, evalout=EVALOUT)
    output: PDF
    shell:
        'Rscript mergeTSVs.R {PDF} "{input}"'

# Clean all the TSV and RData for the specified configuration. E.g. to rerun everything with a new sveval version.
rule clean:
    params:
        tsv=expand('tsv/{exp}-{method}-{sample}-{region}-{eval}-{evalout}.tsv',
                   exp=EXPS, method=METHODS,
                   sample=SAMPLES, region=REGS, eval=EVAL, evalout=EVALOUT),
        rdata=expand('rdata/sveval-{exp}-{method}-{sample}-{region}-{eval}.RData',
                     exp=EXPS, method=METHODS,
                     sample=SAMPLES, region=REGS, eval=EVAL)
    shell:
        'rm -rf {params.tsv} {params.rdata}'

# unzip reference fasta
rule unzip_reference:
    input: '{ref}.fa{sta}.gz'
    output: '{ref}.fa{sta, (sta)?}'
    shell: "gunzip -c {input} > {output}"

# bgzip a VCF file
rule bgzip:
    input: '{vcf}.vcf'
    output: '{vcf}.vcf.gz'
    envmodules:
        config['envm']['bgzip']
    shell:
        'bgzip -c {input} > {output}'

# normalize a VCF using bcftools
rule vcfnorm:
    input:
        vcf="vcf/{exp}-{method}-{sample}.vcf.gz",
        ref=REF
    output:
        "vcf/{exp}-{method}-{sample}.norm.vcf.gz"
    envmodules:
        config['envm']['bgzip'], config['envm']['bcftools']
    shell:
<<<<<<< HEAD
        'bcftools view {input.vcf} --exclude \'GT="0" || GT="." || GT="1"\' | bcftools norm - --fasta-ref {input.ref} --multiallelic -both | bcftools norm - --fasta-ref {input.ref} --multiallelic +both | bgzip > {output}'
=======
        """
        bcftools view {input.vcf} --exclude \'GT="0" || GT="." || GT="1"\' | bcftools norm - --fasta-ref {REF} --multiallelic -both | bcftools norm - --fasta-ref {REF} --multiallelic +both | bgzip > {output}
        """
>>>>>>> master

# function to eventually define more complex file inputs (e.g. to analyze different datasets with different reference versions)
def evalinputs(wildcards):
    ins = {}
    ins['vcf'] = 'vcf/{}-{}-{}.norm.vcf.gz'.format(wildcards.exp, wildcards.method,
                                                   wildcards.sample)
    ins['truth'] = 'vcf/{}-truth-baseline.norm.vcf.gz'.format(wildcards.exp)
    if wildcards.region in config:
        ins['bed'] = config[wildcards.region]        
    return ins

# run sveval on inputs. Creates a R object in 'rdata' folder
rule sveval:
    input:
        unpack(evalinputs)
    output:
        "rdata/sveval-{exp}-{method}-{sample}-{region}-{eval}.RData"
    params:
        bed=lambda wildcards, input: 'NA' if wildcards.region not in config else input['bed']
    resources:
        mem_mb=8000,
        runtime=30
    envmodules:
        config['envm']['sveval']
    shell:
        'Rscript sveval.R {input.vcf} {input.truth} {wildcards.sample} {INV} {params.bed} {wildcards.eval} {output} {MIN_COV}'

# extract some information and write TSVs in the 'tsv' folder
rule parseeval:
    input:
        "rdata/sveval-{exp}-{method}-{sample}-{region}-{eval}.RData"
    output:
        pr="tsv/{exp}-{method}-{sample}-{region}-{eval}-prcurve.tsv",
        ps="tsv/{exp}-{method}-{sample}-{region}-{eval}-persize.tsv"
    envmodules:
        config['envm']['sveval']
    shell:
        "Rscript parseeval.R {input} {output}"
